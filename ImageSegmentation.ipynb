{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ypZeIW3NCP-O",
        "f_BM7bWJLnai",
        "aeRLVFhHXEHF",
        "-iEJJLIRPpqz",
        "yZSROAWI_TCY",
        "-3fTj9-8YLPi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erickmu1/Image-Segmentation/blob/E/ImageSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Fje7Mu90f2"
      },
      "source": [
        "# APS360: Image Segmentation #\n",
        "\n",
        "### **Team 5** ###\n",
        "- Bonnie He\n",
        "- Erick Mejia Uzeda\n",
        "- Hannah Lee\n",
        "\n",
        "## Project Description ##\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Elu3WwbW9uAf"
      },
      "source": [
        "# Imports + Global Variables #\n",
        "\n",
        "Here we import all required libraries and define any useful variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWjctfdF9y8z"
      },
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data storage/loading\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Global Variables\n",
        "DRIVE_ROOT = '/content/drive'\n",
        "COLAB_ROOT = 'My Drive/Colab Notebooks'\n",
        "\n",
        "ROOT = os.path.join(*[ DRIVE_ROOT, COLAB_ROOT, 'Image-Segmentation' ])\n",
        "\n",
        "BACKGROUND_ID = -1  # TODO: actually determine a unique ID for 'background'\n",
        "MAX_LABELS = 16     # Maximum number of labels we will keep\n",
        "IN_CHANNELS = 4     # RGBD images have 4 channels\n",
        "IN_DIM = (530, 730) # Dimensions of RGBD images"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcuozbZN5ruV",
        "outputId": "8f84fd96-bf49-4b43-b539-79d2987dc61d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Link to Google Drive\n",
        "drive.mount(DRIVE_ROOT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DETWb7mU-3_s"
      },
      "source": [
        "# Data Loading #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERXJz_dd9zKW"
      },
      "source": [
        "# Code for loading data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6dR-H5-_HeH"
      },
      "source": [
        "# Data Pre-processing #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypZeIW3NCP-O"
      },
      "source": [
        "## Pre-computing Features from other ML models ##\n",
        "\n",
        "We may have parts of the full ML pipeline implemented and others not. To speed up the training process, it is beneficial to precompute features resulting from a model and save them.\n",
        "\n",
        "**Note:** Features are saved in such a format that once re-loaded, they can be passed directly into a `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JYyF3N7_QMU"
      },
      "source": [
        "# Compute and Save Features from 'model'\n",
        "def save_features(model, data_loader, file_name, dir=ROOT, use_cuda=False):\n",
        "  features = []\n",
        "\n",
        "  for input, label in data_loader:\n",
        "    # Enable CUDA\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      input = input.cuda()\n",
        "      label = label.cuda()\n",
        "    \n",
        "    # Compute features\n",
        "    with torch.no_grad():\n",
        "      output = model(input)\n",
        "\n",
        "    # Cache resulting features\n",
        "    features.extend(output.cpu())\n",
        "  \n",
        "  # Save computed features using pickle\n",
        "  save_path = os.path.join(dir, file_name + '.pickle')\n",
        "\n",
        "  with open(save_path, 'wb+') as f:\n",
        "    pickle.dump(features, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AahfXgL2JUjB"
      },
      "source": [
        "# Load features\n",
        "def load_features(file_name, dir=ROOT):\n",
        "  file_path = os.join.path(dir, file_name + '.pickle')\n",
        "\n",
        "  # Load features using pickle\n",
        "  with open(file_path, 'rb') as f:\n",
        "    features = pickle.load(f)\n",
        "  \n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_BM7bWJLnai"
      },
      "source": [
        "## Grouping Background Segments ##\n",
        "\n",
        "Our dataset has many labels for different categories. Since our goal is to segment non-background items that are *distinct*, we will pre-process the raw segmentation maps to group relevant labels/categories that could be considered as *background*.\n",
        "\n",
        "The following are grouped together: (Background)\n",
        "- `floor`\n",
        "- `wall`\n",
        "- `ceiling`\n",
        "- `window`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IaMKPLZMhul"
      },
      "source": [
        "# Group all 'background' segments into one category\n",
        "def group_background(seg_maps):\n",
        "  # ASSUME: seg_maps is a np.array with dimensions (num_samples x [image_dims])\n",
        "  # NOTE: this function modifies seg_maps itself!\n",
        "\n",
        "  relevant_labels = [ 'floor', 'wall', 'ceiling', 'window' ]\n",
        "  relevant_ids = [ 0, 1, 2, 3 ]  # TODO: get *actual* numerical IDs\n",
        "\n",
        "  # Retrieve indices (pixels) of relevant labels\n",
        "  indices = np.isin(seg_maps, relevant_ids)\n",
        "  \n",
        "  # Associate such indices (pixels) as 'background'\n",
        "  seg_maps[indices] = BACKGROUND_ID"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYww3gwsOjee"
      },
      "source": [
        "## Dealing with Label Permutation and Number of Segments ##\n",
        "\n",
        "Our model will not particularly care what label is associated to segments, hence we prefer to refer to a segment by its segment ID. To re-iterate, our model does not care about what the value of the segment ID is for any given segment, what will dictate if our model is working if it can properly distinguish two **distinct** segments. Thus given an outputted segmentation map, any same segmentation map but with the segment IDs permutted is equally valid. Moreover, our model (in theory) should be invariant to more than permutation, that is any value can be assigned to a segment, as long as distinct segments have distinct IDs.\n",
        "\n",
        "Next, the number of segments depends generally on the number of objects in the scene, so it not known a priori for new samples. This suggests the use of a recurrent architecture but once again, the order in which the segments would be generated is not of importance. In general, dealing with a variable number of possible segments must be accounted for in the model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeRLVFhHXEHF"
      },
      "source": [
        "### Ideas: ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x45JwzcmsEBy"
      },
      "source": [
        "- Use a permutation invariant loss function:https://openreview.net/pdf?id=rJxpuoCqtQ\n",
        "  - A major issue is that the number of segments produced for an image is not fixed, whereas this paper assumes the number of features `F` is known.\n",
        "  - Should we not upper bound the outputs and round each pixel value to the nearest integer as to define its *segment ID*? How sensitive to small weight variantions would our model be? How dependent on the segment ID values temselves will the model be?\n",
        "- Should we use a Recurrent Architecture?\n",
        "  - That is: for each image\n",
        "    1. extract the \"largest\" label\n",
        "    2. remove all pixels from input that correspond to the segment meant to be removed\n",
        "    3. feed in new image and repeat from step 1.\n",
        "  - Note that we will need to either pre-process many images during training (which will make it slow) or cache multiple variants of an image which remove one segment at a time (can grow large if image has many segments)\n",
        "    - Also need to pre-process and \"order\" segments by how \"big\" they are (need to compute pixel area of each segment and order them before making \"inputs\" that have the relevant segments removed)\n",
        "  - We could possibly apply a *Recurrent Pipeline* to our baseline model (k-means) too!\n",
        "- Say we generate all segments from the image in one-pass of the model (simple autoencoder architecture)\n",
        "  - How do we deal with segment ID permutations (and even just different IDs in general, as long as the correct distinct segments have distinct IDs)?\n",
        "  - How do we encode each segment ID?\n",
        "\n",
        "**KEY IDEA:** What if we followed the convention that the largest segment (other than the background) must have the largest (smallest?) ID? Could this additional rule be learned by the model?\n",
        "- If yes, then we resolved the issue of segment ID permutation\n",
        "  - What happens for segments of comparable size? (to think about later)\n",
        "- Could we then also apply *integer thresholding* (or some other thresholding) to identify each distinct segment? This would avoid the need to use a recurrent architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qAJq8-dgEWA"
      },
      "source": [
        "### Sorting Segments by Size ###\n",
        "\n",
        "To address the issues outlined above of the semantic associated with each segment's label and permutation (or the only necessary distinctness requirement) of each segment label, we will sort segments from largest to smallest. The following convention will be assumed and our hope is that the machine learning model can learn this rule:\n",
        "- Background ~ `label = 0`\n",
        "- Largest Segment ~ `label = 1`\n",
        "- Second Largest Segment ~ `label = 2`\n",
        "- `...`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpD8IzpjgTeb"
      },
      "source": [
        "# ASSUME: relevant labels have been grouped into BACKGROUND_ID\n",
        "def sort_segments_by_size(seg_map, max_labels=np.infty):\n",
        "  # Get list of segment labels found in the image\n",
        "  old_labels = np.unique(seg_map)\n",
        "\n",
        "  # Count the number of pixels for each segment\n",
        "  pixel_count = { label : 0 for label in old_labels }\n",
        "\n",
        "  for r in range(seg_map.shape[0]):\n",
        "    for c in range(seg_map.shape[1]):\n",
        "      pixel_count[seg_map[r,c]] += 1\n",
        "\n",
        "  # Special case: background must always have the largest pixel count as to\n",
        "  # enforce background label = 0\n",
        "  if BACKGROUND_ID in pixel_count:\n",
        "    pixel_count[BACKGROUND_ID] = np.infty\n",
        "  else:\n",
        "    print('No Background in Segmentation Map - Did you forget to pre-process?')\n",
        "  \n",
        "  # Sort by pixel count\n",
        "  sorted_labels = sorted(pixel_count, key=lambda label: pixel_count[label], reverse=True)\n",
        "\n",
        "  # Keep only the max_lables largest labels\n",
        "  sorted_labels = sorted_labels[:min(max_labels, len(sorted_labels))]\n",
        "  new_labels = { old_label: new_label for (new_label, old_label) in enumerate(sorted_labels) }\n",
        "  \n",
        "  # Create new segmentation map using new labels\n",
        "  sorted_seg_map = np.zeros(seg_map.shape)\n",
        "\n",
        "  for r in range(seg_map.shape[0]):\n",
        "    for c in range(seg_map.shape[1]):\n",
        "      sorted_seg_map[r,c] = new_labels[seg_map[r,c]]\n",
        "  \n",
        "  return sorted_seg_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmCG2yRPlgMC",
        "outputId": "d2a2b540-4903-491e-d1a2-10e2d636aea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "# TEST\n",
        "seg_map = plt.imread(os.path.join(ROOT, 'Data/img-000007.png'))\n",
        "fig, axs = plt.subplots(2)\n",
        "\n",
        "# Plot input image (semantic labels)\n",
        "mappable = axs[0].imshow(seg_map, cmap='inferno')\n",
        "axs[0].set_title('Semantic Labels')\n",
        "axs[0].axis('off')\n",
        "fig.colorbar(mappable, ax=axs[0])\n",
        "\n",
        "sorted_map = sort_segments_by_size(seg_map)\n",
        "\n",
        "# Plot output image (labels by segment size)\n",
        "mappable = axs[1].imshow(sorted_map, cmap='inferno')\n",
        "axs[1].set_title('Labels by Segment Size')\n",
        "axs[1].axis('off')\n",
        "fig.colorbar(mappable, ax=axs[1]);\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No Background in Segmentation Map - Did you forget to pre-process?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iEJJLIRPpqz"
      },
      "source": [
        "## Data Augmentation (Optional) ##\n",
        "\n",
        "See if we can apply homographies on RGBD + ground truth segmentation map and if we can add noise to the RGBD images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvnnX-ZvQisd"
      },
      "source": [
        "# Code for homographic transformation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wubp1JkQnwY"
      },
      "source": [
        "# Code for adding noise to {RGB, Depth}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZSROAWI_TCY"
      },
      "source": [
        "# Baseline model: k-means Algorithm #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7E5TBh9_ZaX"
      },
      "source": [
        "# Code for k-means algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdEVNEbg_gAU"
      },
      "source": [
        "# Training Pipeline #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lxwI7pS_o6L"
      },
      "source": [
        "# Code for the training pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3fTj9-8YLPi"
      },
      "source": [
        "## Compute Accuracy ##\n",
        "\n",
        "Computes accuracy of a model given a `DataLoader`. Note that the notion of accuracy is not straightforward for tasks other than classification and thus must handled with care as we attempt to quantify how well our models perform!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fds65CcmYVQb"
      },
      "source": [
        "def get_classifier_accuracy(model, data_loader, use_cuda=False):\n",
        "  correct, total = 0, 0\n",
        "\n",
        "  for inputs, targets in data_loader:\n",
        "    # Enable CUDA\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      inputs = inputs.cuda()\n",
        "      targets = targets.cuda()\n",
        "    \n",
        "    # Compute prediction\n",
        "    outputs = model(inputs)\n",
        "    preds = outputs.max(1, keepdim=True)[1]\n",
        "\n",
        "    # Tally\n",
        "    correct += preds.eq(targets.view_as(preds)).sum().item()\n",
        "    total += inputs.size(0)\n",
        "  \n",
        "  return float(correct) / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF3Mf3yQX-H1"
      },
      "source": [
        "## Train Models ##\n",
        "\n",
        "The training pipeline is rather consistent among feedforward classifier models. Functions for training will wrap extra desired functionality to accomodate model requirements.\n",
        "\n",
        "**TODO:** Wrap common iteration loops in a function, allowing customizations where needed (e.g. running a model through a data_loader is a very common process and we can pass in custom functions to extract relevant data, pre-process [add noise], optionally computing accuracy and such).\n",
        "\n",
        "**TODO:** Wrap plotting functions for training curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kLyE4M9nJjP"
      },
      "source": [
        "# TODO: add model defined hyperparameters\n",
        "def model_path(model, batch_size, learning_rate, epoch, root=''):\n",
        "  path = 'model_{0}_bs{1}_lr{2}_epoch{3}'.format(model.name,\n",
        "                                                 batch_size,\n",
        "                                                 learning_rate,\n",
        "                                                 epoch)\n",
        "  return os.path.join(dir, path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1paUfzUXIzd"
      },
      "source": [
        "def train_classifier(model, train_loader, val_loader, use_cuda=False, \n",
        "                     learning_rate=1e-3, num_epochs=20):\n",
        "  torch.manual_seed(1000)\n",
        "\n",
        "  # Optimization settings\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Cache loss/accuracy\n",
        "  train_loss, val_loss = [], []\n",
        "  train_acc, val_acc = [], []\n",
        "\n",
        "  print('Training Start!')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    ### TRAIN model ###\n",
        "    running_loss = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "      # Enable CUDA\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "      \n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Update running loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "    \n",
        "    train_loss.append(running_loss / len(train_loader.dataset))\n",
        "\n",
        "    ### Compute VALIDATION loss ###\n",
        "    running_loss = 0\n",
        "\n",
        "    for inputs, targets in val_loader:\n",
        "      # Enable CUDA\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "      \n",
        "      # Forward pass\n",
        "      with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      # Update running loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "    \n",
        "    val_loss.append(running_loss / len(val_loader.dataset))\n",
        "\n",
        "    # Compute accuracy\n",
        "    train_acc.append(get_classifier_accuracy(model, train_loader, use_cuda))\n",
        "    val_acc.append(get_classifier_accuracy(model, val_loader, use_cuda))\n",
        "\n",
        "    print('Epoch {} (accuracy): {} train, {} val'.format(epoch, train_acc[-1], val_acc[-1]))\n",
        "\n",
        "    # Checkpoint model\n",
        "    # Q: do we want to save checkpoints to our Drive?\n",
        "    path = model_path(model, train_loader.batch_size, learning_rate, epoch)\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "  ### Plot Training Curves ###\n",
        "  fig, axs = plt.subplots(2)\n",
        "\n",
        "  # Loss\n",
        "  axs[0].plot(train_loss)\n",
        "  axs[0].plot(val_loss)\n",
        "\n",
        "  axs[0].legend(('Train', 'Validation'))\n",
        "  axs[0].set_title('Train / Validation Loss')\n",
        "  axs[0].set(xlabel='Epochs', ylabel='Loss')\n",
        "\n",
        "  # Accuracy\n",
        "  axs[1].plot(train_acc)\n",
        "  axs[1].plot(val_acc)\n",
        "\n",
        "  axs[1].legend(('Train', 'Validation'))\n",
        "  axs[1].set_title('Train / Validation Accuracy')\n",
        "  axs[1].set(xlabel='Epochs', ylabel='Accuracy')\n",
        "\n",
        "  plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XAE6r2qqVCF"
      },
      "source": [
        "Autoencoders have a slightly different pipeline and can be adjusted to improve robustness."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EXJYtZLqhFf"
      },
      "source": [
        "# Train AutoEncoder that produces Segmentation Maps\n",
        "# NOTE: Each pixel of the Segmentation Map is a one-hot encoding\n",
        "def train_autoencoder(model, train_loader, val_loader, use_cuda=False, \n",
        "                     learning_rate=1e-3, num_epochs=20):\n",
        "  torch.manual_seed(1000)\n",
        "\n",
        "  # Optimization settings\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Cache loss\n",
        "  # TODO: add accuracy\n",
        "  train_loss, val_loss = [], []\n",
        "\n",
        "  print('Training Start!')\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    ### TRAIN model ###\n",
        "    running_loss = 0\n",
        "\n",
        "    for inputs, _ in train_loader:\n",
        "      # TODO: enable input pre-processing (e.g. add noise)\n",
        "      # Enable CUDA\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "      \n",
        "      # Forward pass\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs.view(-1, MAX_LABELS), inputs.view(-1,1).squeeze())\n",
        "\n",
        "      # Backward pass\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Update running loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "    \n",
        "    train_loss.append(running_loss / len(train_loader.dataset))\n",
        "\n",
        "    ### Compute VALIDATION loss ###\n",
        "    running_loss = 0\n",
        "\n",
        "    for inputs, _ in val_loader:\n",
        "      # TODO: enable input pre-processing (e.g. add noise)\n",
        "      # Enable CUDA\n",
        "      if use_cuda and torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "      \n",
        "      # Forward pass\n",
        "      with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "      loss = criterion(outputs.view(-1, MAX_LABELS), inputs.view(-1,1).squeeze())\n",
        "\n",
        "      # Update running loss\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "    \n",
        "    val_loss.append(running_loss / len(val_loader.dataset))\n",
        "\n",
        "    print('Epoch {} (loss): {} train, {} val'.format(epoch, train_loss[-1], val_loss[-1]))\n",
        "\n",
        "    # Checkpoint model\n",
        "    # Q: do we want to save checkpoints to our Drive?\n",
        "    path = model_path(model, train_loader.batch_size, learning_rate, epoch)\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "  ### Plot Training Curves ###\n",
        "  plt.plot(train_loss)\n",
        "  plt.plot(val_loss)\n",
        "\n",
        "  plt.legend(('Train', 'Validation'))\n",
        "  plt.title('Train / Validation Loss')\n",
        "  \n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzbiJDXb_tya"
      },
      "source": [
        "# Model Implementation #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdaj_g1x4TaD"
      },
      "source": [
        "## Construct Segmentation Maps using a Convolutional Autoencoder ##\n",
        "\n",
        "This model is not strictly a convolutional autoencoder, since we will compare our reconstructed output to the corresponding segmentation map and not the input RGBD image.\n",
        "\n",
        "**NOTE:**\n",
        "- Input size is `(4, 530, 730)`\n",
        "- Output size is `(MAX_LABELS, 530, 730)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw0p3imN_CVT"
      },
      "source": [
        "### Helper Functions ###\n",
        "\n",
        "# Ensures a Convolution Layer is fully specified\n",
        "def get_conv_dict(in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "  conv_dict = {\n",
        "      'i': in_channels,\n",
        "      'o': out_channels,\n",
        "      'k': kernel_size,\n",
        "      's': stride,\n",
        "      'p': padding\n",
        "  }\n",
        "  return conv_dict\n",
        "\n",
        "# Ensures a Transpose Convolution Layer is fully specified\n",
        "def get_convT_dict(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0):\n",
        "  convT_dict = {\n",
        "      'i': in_channels,\n",
        "      'o': out_channels,\n",
        "      'k': kernel_size,\n",
        "      's': stride,\n",
        "      'p': padding,\n",
        "      'op': output_padding\n",
        "  }\n",
        "  return convT_dict\n",
        "\n",
        "# Given input/output and conv layers, compute transpose conv layers\n",
        "def get_convT_layers(conv_layers, image_size=IN_DIM, output_channels=MAX_LABELS, print_Fmaps=False):\n",
        "  # Cache the size / dimension (w x h) of each intermediate feature map\n",
        "  fmaps = [ image_size ]\n",
        "\n",
        "  # Compute feature map dimensions after each convolutional layer\n",
        "  for layer in conv_layers:\n",
        "    w_in, h_in = fmaps[-1]\n",
        "    \n",
        "    w_out = (w_in + 2 * layer['p'] - layer['k']) // layer['s'] + 1\n",
        "    h_out = (h_in + 2 * layer['p'] - layer['k']) // layer['s'] + 1\n",
        "\n",
        "    fmaps.append((w_out, h_out))\n",
        "  \n",
        "  if print_Fmaps:\n",
        "    print('Feature Maps (w,h):', fmaps)\n",
        "  \n",
        "  # Reverse lists for decoding\n",
        "  rev_fmaps = list(reversed(fmaps))\n",
        "  rev_conv_layers = list(reversed(conv_layers))\n",
        "\n",
        "  # Determine appropriate transpose convolution layers\n",
        "  convT_layers = []\n",
        "\n",
        "  for idx in range(len(rev_conv_layers)):\n",
        "    # Get relevant parameters\n",
        "    layer = rev_conv_layers[idx]\n",
        "\n",
        "    fmap_in = rev_fmaps[idx]\n",
        "    fmap_out = rev_fmaps[idx + 1]\n",
        "\n",
        "    w_in, h_in = fmap_in\n",
        "    w_out, h_out = fmap_out\n",
        "\n",
        "    # Compute required output padding\n",
        "    w_pout = w_out - layer['s'] * (w_in - 1) + 2 * layer['p'] - layer['k']\n",
        "    h_pout = h_out - layer['s'] * (h_in - 1) + 2 * layer['p'] - layer['k']\n",
        "\n",
        "    # Append associated transpose convolutional layer\n",
        "    convT_layers.append(get_convT_dict(in_channels=layer['o'], out_channels=layer['i'],\n",
        "                                       kernel_size=layer['k'], stride=layer['s'], \n",
        "                                       padding=layer['p'], output_padding=(w_pout, h_pout)))\n",
        "  \n",
        "  # Ensure last layer outputs specified number of channels\n",
        "  convT_layers[-1]['o'] = output_channels\n",
        "\n",
        "  return convT_layers"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R14JUk6S_xmJ"
      },
      "source": [
        "### Encoder (RBGD --> Embedding) ###\n",
        "\n",
        "class ConvE(nn.Module):\n",
        "  def __init__(self, conv_layers):\n",
        "    super(ConvE, self).__init__()\n",
        "    self.name = 'convE'\n",
        "    self.layers = []\n",
        "\n",
        "    # Create Architecture\n",
        "    for layer in conv_layers:\n",
        "      self.layers.append(nn.Conv2d(in_channels=layer['i'], out_channels=layer['o'],\n",
        "                                   kernel_size=layer['k'], stride=layer['s'], \n",
        "                                   padding=layer['p']))\n",
        "\n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = F.relu(layer(x))\n",
        "\n",
        "    return x\n",
        "\n",
        "### Decoder (Embedding --> MAX_LABELS one-hot encoding per pixel of RGBD) ###\n",
        "\n",
        "class ConvD(nn.Module):\n",
        "  def __init__(self, convT_layers):\n",
        "    super(ConvD, self).__init__()\n",
        "    self.name = 'convD'\n",
        "    self.layers = []\n",
        "\n",
        "    for layer in convT_layers:\n",
        "      self.layers.append(nn.ConvTranspose2d(in_channels=layer['i'], out_channels=layer['o'],\n",
        "                                            kernel_size=layer['k'], stride=layer['s'],\n",
        "                                            padding=layer['p'], output_padding=layer['op']))\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Do not apply ReLU on last layer\n",
        "    for layer in self.layers[:-1]:\n",
        "      x = F.relu(layer(x))\n",
        "\n",
        "    # NOTE: assume will use BCEWithLogitsLoss (do not apply sigmoid)\n",
        "    return self.layers[-1](x)\n",
        "\n",
        "### Convolutional \"Autoencoder\" ###\n",
        "\n",
        "class ConvAE(nn.Module):\n",
        "  def __init__(self, conv_layers, image_size=IN_DIM, out_channels=MAX_LABELS):\n",
        "    super(ConvAE, self).__init__()\n",
        "    self.name = 'convAE'\n",
        "\n",
        "    # Create Encoder\n",
        "    self.encoder = ConvE(conv_layers)\n",
        "\n",
        "    # Create Decoder\n",
        "    convT_layers = get_convT_layers(conv_layers, image_size=image_size, output_channels=out_channels)\n",
        "    self.decoder = ConvD(convT_layers)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.decoder(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWRvEQcgLas0",
        "outputId": "cdcedd8b-9e16-49ed-9ad1-b2634fa42f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# TEST\n",
        "# NOTE: make sure N(i)_in == N(i-1)_out (# Channels Agree)\n",
        "encoder_architecture = [ get_conv_dict(IN_CHANNELS, 6, 8), \n",
        "                         get_conv_dict(6, 10, 4, 2),\n",
        "                         get_conv_dict(10, 12, 6) ]\n",
        "print('ENCODER')\n",
        "print(encoder_architecture)\n",
        "\n",
        "decoder_architecture = get_convT_layers(encoder_architecture, print_Fmaps=True)\n",
        "\n",
        "print('DECODER')\n",
        "print(decoder_architecture)\n",
        "\n",
        "convAE = ConvAE(encoder_architecture)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ENCODER\n",
            "[{'i': 4, 'o': 6, 'k': 8, 's': 1, 'p': 0}, {'i': 6, 'o': 10, 'k': 4, 's': 2, 'p': 0}, {'i': 10, 'o': 12, 'k': 6, 's': 1, 'p': 0}]\n",
            "Feature Maps (w,h): [(530, 730), (523, 723), (260, 360), (255, 355)]\n",
            "DECODER\n",
            "[{'i': 12, 'o': 10, 'k': 6, 's': 1, 'p': 0, 'op': (0, 0)}, {'i': 10, 'o': 6, 'k': 4, 's': 2, 'p': 0, 'op': (1, 1)}, {'i': 6, 'o': 16, 'k': 8, 's': 1, 'p': 0, 'op': (0, 0)}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}