{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSegmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP7yLZc9tKGa9v4BfW7bejh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erickmu1/Image-Segmentation/blob/E/ImageSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Fje7Mu90f2"
      },
      "source": [
        "# APS360: Image Segmentation #\n",
        "\n",
        "### **Team 5** ###\n",
        "- Bonnie He\n",
        "- Erick Mejia Uzeda\n",
        "- Hannah Lee\n",
        "\n",
        "## Project Description ##\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CUYUzA7EoEN"
      },
      "source": [
        "# Imports + Global Variables #\n",
        "\n",
        "Here we import all required libraries and define any useful variables. (Feel free to improve this description)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAm7Ch3PFQIA"
      },
      "source": [
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data storage/loading\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "# Global Variables\n",
        "ROOT = '\\\\'\n",
        "BACKGROUND_ID = 0 # TODO: actually determine a unique ID for 'background'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DETWb7mU-3_s"
      },
      "source": [
        "# Data Loading #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERXJz_dd9zKW"
      },
      "source": [
        "# Code for loading data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6dR-H5-_HeH"
      },
      "source": [
        "# Data Pre-processing #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypZeIW3NCP-O"
      },
      "source": [
        "## Pre-computing Features from other ML models ##\n",
        "\n",
        "We may have parts of the full ML pipeline implemented and others not. To speed up the training process, it is beneficial to precompute features resulting from a model and save them.\n",
        "\n",
        "**Note:** Features are saved in such a format that once re-loaded, they can be passed directly into a `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JYyF3N7_QMU"
      },
      "source": [
        "# Compute and Save Features from 'model'\n",
        "def save_features(model, data_loader, file_name, dir=ROOT, use_cuda=False):\n",
        "  features = []\n",
        "\n",
        "  for input, label in data_loader:\n",
        "    # Enable CUDA\n",
        "    if use_cuda and torch.cuda.is_available():\n",
        "      input = input.cuda()\n",
        "      label = label.cuda()\n",
        "    \n",
        "    # Compute features\n",
        "    with torch.no_grad():\n",
        "      output = model(input)\n",
        "\n",
        "    # Cache resulting features\n",
        "    features.extend(output.cpu())\n",
        "  \n",
        "  # Save computed features using pickle\n",
        "  save_path = os.path.join(dir, file_name + '.pickle')\n",
        "\n",
        "  with open(save_path, 'wb+') as f:\n",
        "    pickle.dump(features, f)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AahfXgL2JUjB"
      },
      "source": [
        "# Load features\n",
        "def load_features(file_name, dir=ROOT):\n",
        "  file_path = os.join.path(dir, file_name + '.pickle')\n",
        "\n",
        "  # Load features using pickle\n",
        "  with open(file_path, 'rb') as f:\n",
        "    features = pickle.load(f)\n",
        "  \n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_BM7bWJLnai"
      },
      "source": [
        "## Grouping Background Segments ##\n",
        "\n",
        "Our dataset has many labels for different categories. Since our goal is to segment non-background items that are *distinct*, we will pre-process the raw segmentation maps to group relevant labels/categories that could be considered as *background*.\n",
        "\n",
        "The following are grouped together: (Background)\n",
        "- `floor`\n",
        "- `wall`\n",
        "- `ceiling`\n",
        "- `window`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IaMKPLZMhul"
      },
      "source": [
        "# Group all 'background' segments into one category\n",
        "def group_background(seg_maps):\n",
        "  # ASSUME: seg_maps is a np.array with dimensions (num_samples x [image_dims])\n",
        "  # NOTE: this function modifies seg_maps itself!\n",
        "\n",
        "  relevant_labels = [ 'floor', 'wall', 'ceiling', 'window' ]\n",
        "  relevant_ids = [ 0, 1, 2, 3 ]  # TODO: get *actual* numerical IDs\n",
        "\n",
        "  # Retrieve indices (pixels) of relevant labels\n",
        "  indices = np.isin(seg_maps, relevant_ids)\n",
        "  \n",
        "  # Associate such indices (pixels) as 'background'\n",
        "  seg_maps[indices] = BACKGROUND_ID"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYww3gwsOjee"
      },
      "source": [
        "## Dealing with Label Permutation ##\n",
        "\n",
        "Our model will not particularly care what label is associated to segments, hence we prefer to refer to a segment by its segment ID. To re-iterate, our model does not care about what the value of the segment ID is for any given segment, what will dictate if our model is working if it can properly distinguish two **distinct** segments. Thus given an outputted segmentation map, any same segmentation map but with the segment IDs permutted is equally valid.\n",
        "\n",
        "TODO: how will we deal with this invariance to segment ID permutation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yq65r9pPqPM"
      },
      "source": [
        "# Code (if any) for pre-processing dataset to account for segment ID permutation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iEJJLIRPpqz"
      },
      "source": [
        "## Data Augmentation (Optional) ##\n",
        "\n",
        "See if we can apply homographies on RGBD + ground truth segmentation map and if we can add noise to the RGBD images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvnnX-ZvQisd"
      },
      "source": [
        "# Code for homographic transformation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wubp1JkQnwY"
      },
      "source": [
        "# Code for adding noise to {RGB, Depth}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZSROAWI_TCY"
      },
      "source": [
        "# Baseline model: k-means Algorithm #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7E5TBh9_ZaX"
      },
      "source": [
        "# Code for k-means algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdEVNEbg_gAU"
      },
      "source": [
        "# Training Pipeline #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lxwI7pS_o6L"
      },
      "source": [
        "# Code for the training pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzbiJDXb_tya"
      },
      "source": [
        "# Model Implementation #"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R14JUk6S_xmJ"
      },
      "source": [
        "# Code for implementing the propsed model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}